# ü§ñ One-Stop AI Model Training Service

This project provides a streamlined, end-to-end pipeline for training and deploying AI language models using custom datasets. Users can upload data, trigger training, and deploy the resulting model as an API‚Äîall integrated with AWS infrastructure.

---

## üìå Overview

This service enables users to:

1. **Upload custom training data to S3**
2. **Fine tune an AI model** based on the uploaded dataset
3. **Package the model and build a FastAPI-based inference server**
4. **Deploy the server to EC2 using infrastructure as code**

## üõ† Technologies Used

- Python for model training and API logic
- HuggingFace Transformers for fine-tuning and inference
- AWS S3 & EC2 for data and deployment
- Docker for packaging
- FastAPI for serving the model
- Terraform for infrastructure deployment

## üîÅ Workflow
1. **Data Ingestion**
    - User uploads a JSON file (formatted for fine-tuning) to a specific S3 bucket.
    - File format example:
      ```json
      [
        {
          "prompt": "You are a shy, AI-based robot assistant. You are very knowledgeable about programming but get nervous talking to people.\nUser: How do I reverse a string in Python?",
          "response": "Assistant: U-um... I think the answer is: You can use slicing like this: my_string[::-1]"
        },
        {
          "prompt": "You are a shy, AI-based robot assistant. You are very knowledgeable about programming but get nervous talking to people.\nUser: What is a lambda function?",
          "response": "Assistant: I-if I may... um... the answer might be: A lambda function is a small anonymous function using the lambda keyword."
        }
      ]
      ```
      
2. **Model Training**
    - The training service pulls the dataset from S3.
    - Initializes and fine-tunes a base language model using the uploaded data.
    - Store the training result in adapter weights and merged model
    - Uploads the both training result to S3.

3. **Model Deployment**
    - Builds a Docker image containing:
        - The trained model
        - A FastAPI app for inference
    - Pushes the image to a container registry 
    - Uses Terraform or another IaC tool (feel free to contribute) to deploy the image to an EC2 instance for hosting.

## Hardware Requirements
- **Required GPU for accelerated model training**

